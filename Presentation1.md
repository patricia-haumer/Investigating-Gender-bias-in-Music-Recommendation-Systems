# ğŸ¤ Presentation Guide: Unheard Voices â€“ Gender Bias in Music Recommendation Systems

## ğŸ¯ 1. Project Motivation

- **Problem:** Music recommender systems often favor male artists.
- **Evidence:** Users wait until track 7â€“8 to hear a female artist (Ferraro et al., 2021).
- **Impact:** Reinforces inequality, reduces visibility for underrepresented artists.

âœ… **Goal:** Detect and mitigate gender bias to create fairer recommendation systems.

---

## ğŸ” 2. Research Questions

1. Does **gender bias** exist in music recommender systems?
2. How do **fairness metrics** like demographic parity reflect this bias?
3. Can tools like **Fairlearn** and **AIF360** reduce bias without hurting performance?

---

## ğŸ§ª 3. Methodology

- **Framework:** Design Science Research (Peffers et al., 2007)
- **Tools:** Python, Jupyter, Fairlearn, AIF360
- **Datasets:** Spotify Million Playlist Dataset + Last.fm (with gender enrichment)

---

## ğŸ› ï¸ 4. Recommender Systems Tested

### ğŸ“ˆ Spotify:
- âœ… Baseline: Popularity-based (Fairlearn)
- âœ… Content-Based: Artist & Genre similarity (Fairlearn, AIF360)

### ğŸµ Last.fm:
- âœ… Baseline: Popularity (Fairlearn)
- âœ… Content-Based: Similarity-based (Fairlearn, AIF360)

---

## ğŸ“Š 5. Evaluation Metrics

- **Fairness:**
  - Demographic Parity
  - Exposure Ratio
  - Disparate Impact
- **Performance:**
  - Accuracy
  - Recommendation Coverage

---

## ğŸ§  6. Key Findings

| Dataset | Method                  | Fairness Improved? | Accuracy Impact |
|---------|--------------------------|---------------------|------------------|
| Spotify | Fairlearn + CBF          | âœ… Yes               | â¬‡ï¸ Minimal       |
| Spotify | AIF360 + CBF             | âœ… Yes               | â¬‡ï¸ Minimal       |
| Last.fm | Fairlearn Baseline       | âœ… Yes               | â¬‡ï¸ Minimal       |
| Last.fm | AIF360 Content-Based     | âœ… Yes               | â¬‡ï¸ Minimal       |

âœ… Bias mitigation is effective **without major loss in performance**.

---

## ğŸš€ 7. Contribution

- Highlighted **real gender bias** in popular music platforms
- Applied **multiple fairness frameworks** for mitigation
- Created a **reproducible workflow** for bias analysis in recommendations

---

## ğŸ“Œ 8. Future Work

- Try **RecBole** or **FaiRecSys** for deeper recommender integration
- Expand analysis to **non-binary** and intersectional identities
- Test on **real user interaction logs**

---

## ğŸ™Œ 9. Team & Acknowledgements

ğŸ‘©â€ğŸ’» Katharina Rosa PÃ¶cher  
ğŸ‘©â€ğŸ’» Patricia Haumer  

Special thanks to WU Vienna and the Data Science & AI II course.

---

## ğŸ”— 10. GitHub Repository

â¡ï¸ [GitHub Project Link](https://github.com/YOUR_USERNAME/unheard-voices-recommender)

